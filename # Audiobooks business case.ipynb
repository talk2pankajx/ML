{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiobooks business case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data. Balance the dataset. Create 3 datasets: training, validation, and test. Save the newly created sets in a tensor friendly format (e.g. *.npz)\n",
    "\n",
    "Since we are dealing with real life data, we will need to preprocess it a bit. This is the relevant code, which is not that hard, but is crucial to creating a good model.\n",
    "\n",
    "If you want to know how to do that, go through the code. In any case, this should do the trick for most datasets organized in the way: many inputs, and then 1 cell containing the targets (supervised learning datasets). Keep in mind that a specific problem may require additional preprocessing.\n",
    "\n",
    "Note that we have removed the header row, which contains the names of the categories. We simply want the data.\n",
    "\n",
    "This code does not include comments - it is the same as the one in the lesson. Please refer to the other file if you want the code with comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data from the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in f:\\anaconda\\envs\\py3-tf2.0\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in f:\\anaconda\\envs\\py3-tf2.0\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in f:\\anaconda\\envs\\py3-tf2.0\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in f:\\anaconda\\envs\\py3-tf2.0\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in f:\\anaconda\\envs\\py3-tf2.0\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "\n",
    "!pip install -U scikit-learn\n",
    "\n",
    "\n",
    "raw_csv_data = np.loadtxt(r'C:\\Users\\91776\\Downloads\\Audiobooks_data.csv', delimiter = ',')\n",
    "\n",
    "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
    "targets_all = raw_csv_data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_one_targets = int(np.sum(targets_all))\n",
    "zero_targets_counter = 0\n",
    "indices_to_remove = []\n",
    "\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] ==0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "            \n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n",
    "targets_equal_priors = np.delete (targets_all, indices_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1788.0 3579 0.49958088851634536\n",
      "225.0 447 0.5033557046979866\n",
      "224.0 448 0.5\n"
     ]
    }
   ],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "train_samples_count = int(0.8*samples_count)\n",
    "validation_samples_count = int(0.1*samples_count)\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]\n",
    "\n",
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the three datasets in *.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Audiobooks_data_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('Audiobooks_data_validation', inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez('Audiobooks_data_test', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data now loading into the vaiables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz=np.load(r'C:\\Users\\91776\\Audiobooks_data_test.npz')\n",
    "\n",
    "train_inputs = npz[\"inputs\"].astype(float)\n",
    "train_targets = npz[\"targets\"].astype(int)\n",
    "\n",
    "npz=np.load(r'C:\\Users\\91776\\Audiobooks_data_validation.npz')\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(float), npz['targets'].astype(int)\n",
    "\n",
    "npz=np.load(r'C:\\Users\\91776\\Audiobooks_data_test.npz')\n",
    "test_inputs, test_targets = npz['inputs'].astype(float), npz['targets'].astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 - 1s - loss: 0.7132 - accuracy: 0.4710 - val_loss: 0.6802 - val_accuracy: 0.5570 - 566ms/epoch - 113ms/step\n",
      "Epoch 2/100\n",
      "5/5 - 0s - loss: 0.6561 - accuracy: 0.6027 - val_loss: 0.6435 - val_accuracy: 0.6353 - 36ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "5/5 - 0s - loss: 0.6141 - accuracy: 0.6942 - val_loss: 0.6151 - val_accuracy: 0.6734 - 36ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "5/5 - 0s - loss: 0.5822 - accuracy: 0.7277 - val_loss: 0.5907 - val_accuracy: 0.6913 - 39ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "5/5 - 0s - loss: 0.5537 - accuracy: 0.7388 - val_loss: 0.5699 - val_accuracy: 0.6980 - 36ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "5/5 - 0s - loss: 0.5303 - accuracy: 0.7433 - val_loss: 0.5507 - val_accuracy: 0.7159 - 44ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "5/5 - 0s - loss: 0.5103 - accuracy: 0.7478 - val_loss: 0.5332 - val_accuracy: 0.7226 - 31ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "5/5 - 0s - loss: 0.4927 - accuracy: 0.7522 - val_loss: 0.5175 - val_accuracy: 0.7360 - 37ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "5/5 - 0s - loss: 0.4769 - accuracy: 0.7545 - val_loss: 0.5029 - val_accuracy: 0.7450 - 36ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "5/5 - 0s - loss: 0.4627 - accuracy: 0.7679 - val_loss: 0.4900 - val_accuracy: 0.7629 - 39ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "5/5 - 0s - loss: 0.4509 - accuracy: 0.7812 - val_loss: 0.4797 - val_accuracy: 0.7696 - 31ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "5/5 - 0s - loss: 0.4402 - accuracy: 0.7835 - val_loss: 0.4697 - val_accuracy: 0.7718 - 35ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "5/5 - 0s - loss: 0.4307 - accuracy: 0.7835 - val_loss: 0.4602 - val_accuracy: 0.7494 - 36ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "5/5 - 0s - loss: 0.4229 - accuracy: 0.7902 - val_loss: 0.4519 - val_accuracy: 0.7539 - 37ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "5/5 - 0s - loss: 0.4162 - accuracy: 0.7879 - val_loss: 0.4442 - val_accuracy: 0.7517 - 33ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "5/5 - 0s - loss: 0.4105 - accuracy: 0.7857 - val_loss: 0.4397 - val_accuracy: 0.7584 - 37ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "5/5 - 0s - loss: 0.4039 - accuracy: 0.7969 - val_loss: 0.4331 - val_accuracy: 0.7584 - 41ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "5/5 - 0s - loss: 0.3982 - accuracy: 0.7902 - val_loss: 0.4280 - val_accuracy: 0.7651 - 32ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "5/5 - 0s - loss: 0.3935 - accuracy: 0.7857 - val_loss: 0.4225 - val_accuracy: 0.7651 - 37ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "5/5 - 0s - loss: 0.3891 - accuracy: 0.7902 - val_loss: 0.4170 - val_accuracy: 0.7562 - 33ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "5/5 - 0s - loss: 0.3848 - accuracy: 0.8214 - val_loss: 0.4117 - val_accuracy: 0.7808 - 32ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "5/5 - 0s - loss: 0.3811 - accuracy: 0.8192 - val_loss: 0.4081 - val_accuracy: 0.7897 - 35ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "5/5 - 0s - loss: 0.3769 - accuracy: 0.8214 - val_loss: 0.4057 - val_accuracy: 0.7629 - 35ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "5/5 - 0s - loss: 0.3738 - accuracy: 0.8013 - val_loss: 0.4050 - val_accuracy: 0.7740 - 46ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "5/5 - 0s - loss: 0.3705 - accuracy: 0.8058 - val_loss: 0.4013 - val_accuracy: 0.7696 - 33ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "5/5 - 0s - loss: 0.3670 - accuracy: 0.8103 - val_loss: 0.3964 - val_accuracy: 0.8031 - 30ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "5/5 - 0s - loss: 0.3644 - accuracy: 0.8304 - val_loss: 0.3944 - val_accuracy: 0.7987 - 32ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "5/5 - 0s - loss: 0.3617 - accuracy: 0.8125 - val_loss: 0.3920 - val_accuracy: 0.7696 - 32ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "5/5 - 0s - loss: 0.3585 - accuracy: 0.8058 - val_loss: 0.3894 - val_accuracy: 0.8098 - 32ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "5/5 - 0s - loss: 0.3562 - accuracy: 0.8147 - val_loss: 0.3891 - val_accuracy: 0.7718 - 32ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "5/5 - 0s - loss: 0.3532 - accuracy: 0.8192 - val_loss: 0.3852 - val_accuracy: 0.7987 - 38ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "5/5 - 0s - loss: 0.3506 - accuracy: 0.8304 - val_loss: 0.3811 - val_accuracy: 0.8031 - 36ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "5/5 - 0s - loss: 0.3487 - accuracy: 0.8259 - val_loss: 0.3811 - val_accuracy: 0.8098 - 35ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "5/5 - 0s - loss: 0.3455 - accuracy: 0.8259 - val_loss: 0.3777 - val_accuracy: 0.7987 - 31ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "5/5 - 0s - loss: 0.3434 - accuracy: 0.8281 - val_loss: 0.3744 - val_accuracy: 0.7987 - 38ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "5/5 - 0s - loss: 0.3412 - accuracy: 0.8304 - val_loss: 0.3722 - val_accuracy: 0.8076 - 37ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "5/5 - 0s - loss: 0.3406 - accuracy: 0.8080 - val_loss: 0.3739 - val_accuracy: 0.7987 - 39ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "5/5 - 0s - loss: 0.3379 - accuracy: 0.8304 - val_loss: 0.3712 - val_accuracy: 0.8121 - 35ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "5/5 - 0s - loss: 0.3359 - accuracy: 0.8326 - val_loss: 0.3678 - val_accuracy: 0.7987 - 35ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "5/5 - 0s - loss: 0.3349 - accuracy: 0.8259 - val_loss: 0.3669 - val_accuracy: 0.8031 - 36ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "5/5 - 0s - loss: 0.3314 - accuracy: 0.8304 - val_loss: 0.3651 - val_accuracy: 0.8076 - 35ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "5/5 - 0s - loss: 0.3303 - accuracy: 0.8214 - val_loss: 0.3634 - val_accuracy: 0.8277 - 43ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "5/5 - 0s - loss: 0.3289 - accuracy: 0.8348 - val_loss: 0.3611 - val_accuracy: 0.8054 - 44ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "5/5 - 0s - loss: 0.3272 - accuracy: 0.8304 - val_loss: 0.3614 - val_accuracy: 0.8031 - 31ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "5/5 - 0s - loss: 0.3242 - accuracy: 0.8348 - val_loss: 0.3597 - val_accuracy: 0.7964 - 34ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "5/5 - 0s - loss: 0.3247 - accuracy: 0.8371 - val_loss: 0.3588 - val_accuracy: 0.7987 - 35ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "5/5 - 0s - loss: 0.3208 - accuracy: 0.8326 - val_loss: 0.3612 - val_accuracy: 0.8367 - 38ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "5/5 - 0s - loss: 0.3226 - accuracy: 0.8371 - val_loss: 0.3591 - val_accuracy: 0.8255 - 38ms/epoch - 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2547ebed4c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 10\n",
    "output_size=2\n",
    "hidden_layer_size = 50\n",
    "# tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                             tf.keras.layers.Dense(hidden_layer_size,activation='relu'),## adding layers to the model\n",
    "                             tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                             tf.keras.layers.Dense(output_size,activation = 'softmax')                                                            \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "max_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "model.fit(train_inputs, train_targets,\n",
    "          batch_size = batch_size,\n",
    "          epochs=max_epochs,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(validation_inputs,validation_targets),\n",
    "          verbose=2\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8438\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
